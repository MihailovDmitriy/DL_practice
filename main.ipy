
import os
import sys
import scipy.io
import scipy.misc
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow
from PIL import Image
#from net_utils import *
import numpy as np
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from keras_preprocessing import image

%matplotlib inline

#Попробуем скопипастить код с другого туториала

#Включение "мгновенного исполнения". Пока плохо понимаю что это
#По умолчанию в tensorflow 2.0 включено поэтому не надо ничего делать
#tf.enable_eager_execution()
print("Eager execution: {}".format(tf.executing_eagerly()))



#Пути до изображений контента и стиля
CONTENT_PATH = 'H:\Google Disk\Materials\ISP\VGG-19\DL_practice\pictures\content\kitten-cat-wallpaper-10.jpg' 
STYLE_PATH =  'H:\Google Disk\Materials\ISP\VGG-19\DL_practice\pictures\style\The_Great_Wave_off_Kanagawa.jpg'

plt.figure(figsize=(10,10))
content = image.load_img(CONTENT_PATH)
style = image.load_img(STYLE_PATH)

plt.subplot(1, 2, 1)
imshow(content, 'Blues')

plt.subplot(1, 2, 2)
imshow(style, 'Blues')
plt.show()



# Слой контента, в который помещается карта объектов
content_layers = ['block5_conv2'] 

# Со слоем стиля немного по-другому
style_layers = ['block1_conv1',\
                'block2_conv1',\
                'block3_conv1', \
                'block4_conv1', \
                'block5_conv1'\
               ]

num_content_layers = len(content_layers)
num_style_layers = len(style_layers)

def get_model():
  """ Создание модели с доступом к промежуточным слоям 
  
  Эта функция будет подгружать модель VGG19 и давать доступ 
  к промежуточным слоям. В дальнейшем эти слои будут использоваться
  для создания собственной модели для изображения.
  Возвращает данные с промежуточных слоёв VGG19 модели.
 
  """
  
  ''' По всей видимости это работает так: конструктор Model 
  принимает в качестве аргументов два параметра начальный и конечный слой.
  Слои в Keras обладают тем свойством что к ним "прицепляются" другие 
  слои и таким образом образуется направленный граф слоев который 
  и составляет архитектуру модели и именно так конструктор получает
  информацию обо всех слоях архитектуры и способу их организации. 
  
  Помимо этого он видимо дает прямой доступ извне только к слоям
  указанным в качестве аргументов (а другие слои видимо приватные)
  '''
  # Тут подгружается модель (weights=’imagenet’)
  vgg = tf.keras.applications.vgg19.VGG19(include_top=False,\
                                          weights='imagenet')
  
  # Этот атрибут, по всей видимости, обозначает что сеть уже обученная.
  # т. е. не будет обучасться
  vgg.trainable = False
  
  ''' Только что были загружены нужные слои с их весами, теперь нам
  нужно указать какие слои будут входящими какие исходящими, чтобы потом
  получать к ним доступ "снаружи" объекта Model
  '''
  
  # Получение соответствующих слоёв стиля и контента 
  style_outputs = [vgg.get_layer(name).output for name in style_layers]
  content_outputs = [vgg.get_layer(name).output for name in content_layers]
  
  model_outputs = style_outputs + content_outputs
  # Построение модели
  return tf.keras.Model(vgg.input, model_outputs)

def get_content_loss(base_content, target):
    # Определение функции потери контента
    return tf.reduce_mean(tf.square(base_content - target))

def gram_matrix(input_tensor):
    # Сначала идёт канал изображения
    channels = int(input_tensor.shape[-1])
    a = tf.reshape(input_tensor, [-1, channels])
    n = tf.shape(a)[0]
    gram = tf.matmul(a, a, transpose_a=True)
    return gram / tf.cast(n, tf.float32)
 
def get_style_loss(base_style, gram_target):
    """Принимает два изображения измерений h, w, c"""
    # высота, ширина и количество фильтров в каждом слое
    height, width, channels = base_style.get_shape().as_list()
    gram_style = gram_matrix(base_style)
    
    return tf.reduce_mean(tf.square(gram_style - gram_target))

def get_feature_representations(model, content_path, style_path):
    """Функция, которая рассчитывает признаки стиля и контента
     
    Эта функция будет просто предварительно подгружать и обрабатывать содержимое и стиль. 
    Затем эти представления пройдут через сеть, чтобы получить промежуточные слои.
    
    Аргументы:
      model: Используемая модель.
      content_path: Путь к изображению содержимого.
      style_path: Путь к изображению стиля.
      
    Возвращает:
      Признаки стиля и контента. 
    """
    # Подгрузка изображений
    content_image = load_and_process_img(content_path)
    style_image = load_and_process_img(style_path)
    
    # Одновременная обработка признаков стиля и контента
    stack_images = np.concatenate([style_image, content_image], axis=0)
    model_outputs = model(stack_images)
    
    # Получение представлений признаков 
    style_features = [style_layer[0] for style_layer in model_outputs[:num_style_layers]]
    content_features = [content_layer[1] for content_layer in model_outputs[num_style_layers:]]
    return style_features, content_features

def compute_loss(model, loss_weights, init_image, gram_style_features, content_features):
    """Эта функция рассчитывает полную потерю.
    
    Аргументы:
      model: Модель с нужными промежуточными слоями.
      loss_weights: Вес каждого компонента для каждой функции потерь. 
        (вес для стиля, для контента и общий).
      init_image: Первичное изображение. Это то изображение, которое в процессе оптимизации будет обновляться.
      gram_style_features: Предварительные вычисления матрицы Грама соответствующих слоёв.
      content_features: Предварительные вычисления нужных слоёв контента.
        
    Возвращает:
      Общие потери, потери для стиля, контента и вариационные потери
    """
    style_weight, content_weight, total_variation_weight = loss_weights
    
    # Прогонка изображение через модель. Это даст представления контента и стиля.
    # Из-за использования мгновенного выполнения, эта модель вызывается как и любая другая функция.
    model_outputs = model(init_image)
    
    style_output_features = model_outputs[:num_style_layers]
    content_output_features = model_outputs[num_style_layers:]
    
    style_score = 0
    content_score = 0
    
    # Суммирует потерю стиля со всех слоёв
    # Тут одинаково взвешиваются потери каждого слоя.
    weight_per_style_layer = 1.0 / float(num_style_layers)
    for target_style, comb_style in zip(gram_style_features, style_output_features):
      style_score += weight_per_style_layer * get_style_loss(comb_style[0], target_style)
      
    # Суммирование потерь контента со всех слоёв
    weight_per_content_layer = 1.0 / float(num_content_layers)
    for target_content, comb_content in zip(content_features, content_output_features):
      content_score += weight_per_content_layer* get_content_loss(comb_content[0], target_content)
    
    style_score *= style_weight
    content_score *= content_weight
    total_variation_score = total_variation_weight * total_variation_loss(init_image)
    
    # Получение суммарной потери
    loss = style_score + content_score + total_variation_score 
    return loss, style_score, content_score, total_variation_score

def compute_grads(cfg):
    with tf.GradientTape() as tape: 
      all_loss = compute_loss(**cfg)
    # Расчёт градиента изображения
    total_loss = all_loss[0]
    return tape.gradient(total_loss, cfg['init_image']), all_loss

def run_style_transfer(content_path, 
                       style_path,
                       num_iterations=1000,
                       content_weight=1e3, 
                       style_weight = 1e-2): 
    display_num = 100
    # В этом случае не нужно обучать каждый слой модели. Поэтому параметр trainability нужно выставить в false.
    model = get_model() 
    for layer in model.layers:
      layer.trainable = False
    
    # Получение представлений признаков стиля и контента (из промежуточных слоёв)
    style_features, content_features = get_feature_representations(model, content_path, style_path)
    gram_style_features = [gram_matrix(style_feature) for style_feature in style_features]
    
    # Загрузка изначального изображения
    init_image = load_and_process_img(content_path)
    init_image = tfe.Variable(init_image, dtype=tf.float32)
    
    # Создание оптимизатора
    opt = tf.train.AdamOptimizer(learning_rate=10.0)
    
    # Отображение промежуточных изображений
    iter_count = 1
    
    # Сохранение лучшего результата
    best_loss, best_img = float('inf'), None
    
    # Создание конфигурации 
    loss_weights = (style_weight, content_weight)
    cfg = {
        'model': model,
        'loss_weights': loss_weights,
        'init_image': init_image,
        'gram_style_features': gram_style_features,
        'content_features': content_features
    }
      
    # Отображение
    plt.figure(figsize=(15, 15))
    num_rows = (num_iterations / display_num) // 5
    start_time = time.time()
    global_start = time.time()
    
    norm_means = np.array(1)
    min_vals = -norm_means
    max_vals = 255 - norm_means   
    for i in range(num_iterations):
      grads, all_loss = compute_grads(cfg)
      loss, style_score, content_score = all_loss
      # grads, _ = tf.clip_by_global_norm(grads, 5.0)
      opt.apply_gradients([(grads, init_image)])
      clipped = tf.clip_by_value(init_image, min_vals, max_vals)
      init_image.assign(clipped)
      end_time = time.time() 
      
      if loss < best_loss:
        # Обновление лучшей потери и изображения 
        best_loss = loss
        best_img = init_image.numpy()
    
      if i % display_num == 0:
        print('Iteration: {}'.format(i))        
        print('Total loss: {:.4e}, ' 
              'style loss: {:.4e}, '
              'content loss: {:.4e}, '
              'time: {:.4f}s'.format(loss, style_score, content_score, time.time() - start_time))
        start_time = time.time()
        
        # Отображение промежуточных изображений
        if iter_count > num_rows * 5: continue 
        plt.subplot(num_rows, 5, iter_count)
        # Используйте метод .numpy(), чтобы получить конкретный numpy-массив
        plot_img = init_image.numpy()
        plot_img = deprocess_img(plot_img)
        plt.imshow(plot_img)
        plt.title('Iteration {}'.format(i + 1))
    
        iter_count += 1
    print('Total time: {:.4f}s'.format(time.time() - global_start))
        
    return best_img, best_loss 

best, best_loss = run_style_transfer(CONTENT_PATH, 
                                     STYLE_PATH)